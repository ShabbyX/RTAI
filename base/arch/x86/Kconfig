mainmenu "RTAI/x86 configuration"

config MODULES
	bool
	default y

config RTAI_VERSION
	string
	default "4.0 (vulcano)"

menu "General"

config RTAI_INSTALLDIR
	string "Installation directory"
	default "/usr/realtime"

	help
	This option defines the directory where the various RTAI
	files will be installed on your target system.
	This directory may be changed if you double-click in the area
	named "Value". The default installation directory is
	/usr/realtime.

config RTAI_LINUXDIR
	string "Linux source tree"
	default "/usr/src/linux"
	help
	This variable contains the directory of your previously
	patched Linux kernel. As explained before, you can change the
	value of the Linux source tree which is fixed by default to
	/usr/src/linux.

endmenu

menu "Machine (x86 / x86_64)"

config RTAI_CPUS
	string "Number of CPUs (SMP-only)"
	default 4
	help
	RTAI has native support for Symmetrical Multi-Processing
	machines. If it is your case, you may want to enter here the
	number of CPUs of your motherboard.

	PAY ATTENTION: the default value is 4.

config RTAI_DIAG_TSC_SYNC
	bool "Diagnose out of sync MP-TSCs"
	default n
	help
	Check alignment of MP-TSCs, against a master CPU, and show them in
	the RTAI HAL proc file system (in TSC count units).

config RTAI_MASTER_TSC_CPU
	depends on RTAI_DIAG_TSC_SYNC
	string "Define the master CPU for aligning MP-TSCs"
	default 0
	help
	Master CPU for diagnosis and correction of TSCs alignment.

config RTAI_TUNE_TSC_SYNC
	depends on RTAI_DIAG_TSC_SYNC
	bool "Tune out of sync MP-TSCs"
	default n
	help
	Use offsets made available by enabling the out of sync diagnosis to
	keep readings of TSCs times as aligned as possible.

endmenu

menu "Base system"

menu "Scheduling options"

config RTAI_SCHED_ISR_LOCK
	bool "Disable immediate rescheduling from within ISRs"
	default n
	help
	RTAI schedules as soon as a higher priority task is awaken in an 
	interrupt handler, i.e. it does not wait to exit the handler itself.
	This is believed to be the best way, since a user that does not want 
	it has just to care calling any scheduling API at the very end of 
	her/his handler.
	Those wanting to have any awaken higher priority task scheduled only
	after exiting the ISR, regardless from where a scheduling API is
	called within the handler, should disable immediate rescheduling 
	from ISRs by enabling this configuration option.

config RTAI_LONG_TIMED_LIST
	bool "Use a binary tree ordering for RTAI schedulers timed lists."
	default n
	help
	RTAI schedulers use a simple ordered linear list for suspended timed
	tasks by default. By enabling this option a binary sort type ordering 
	is used. Such a scheme requires far less, albeit far more complex, 
	operations to set up a time ordered list of wake up times. So when 
	one has not so many tasks on the timed lists this option might not 
	be worth having. The actual threshold value depends on many factors,
	CPU power being the main one. So it is up to you to make a choice.
	If you have many tens or even hundred(s) of timed tasks then it is 
	likely that it might be worth enabling this option.

config RTAI_SCHED_8254_LATENCY
	string "8254 tuning latency (ns)"
	default 4700
	help
	The anticipation time to be used to program the hard timer, in oneshot
	mode, for the next scheduling shot in order to compensate for the
	programming overhead needed to determine the right firing time.
	This parameter has no effect when the periodic mode is used.
	It should be determined with the calibration support provided by RTAI, 
	starting from a tentative configuration; better if set to zero
	for the very first calibration. 
	The same value is used as a compromise for both kernel and 
	user space tasks. Which means that for an on time user space task there 
	could be some anticipation, i.e. a negative latency, for a kernel space
	task. The busy alignment option should be used in such a case to
	provide a compromised on time scheduling for both, albeit at a 
	negligible added cost.

config RTAI_SCHED_APIC_LATENCY
	string "APIC tuning latency (ns)"
	default 3944
        help
        The anticipation time to be used to program the hard timer, in oneshot
        mode, for the next scheduling shot in order to compensate for the
        programming overhead needed to determine the right firing time.
	This parameter has no effect when the periodic mode is used.
	It should be determined with the calibration support provided by RTAI, 
	starting from a tentative configuration; better if set to zero
	for the very first calibration. 
	The same value is used as a compromise for both kernel and 
	user space tasks. Which means that for an on time user space task there 
	could be some anticipation, i.e. a negative latency, for a kernel space
	task. The busy alignment option could be used in such a case to
	provide a compromised on time scheduling for both, albeit at a 
	negligible added cost.

config RTAI_BUSY_TIME_ALIGN
	bool "Busy wait to ensure resume time alignment"
	default n
	help
	In oneshot mode there is a calibrated anticipation of the timer
	firing to compensate for the time overhead consumed in scheduling. 
	Sometimes, either because of a bad calibration or purposely, it is
	possible to anticipate the scheduling by setting a slightly larger than 
	needed anticipation. In such cases with this option one can be sure to
	achieve the desired scheduling time at the expense of waisting some
	processor time. Useful to achieve both more precise scheduled deadlines
	and non negative latency values.
	Do not set it if a hard periodic timer is to be used.
	Since a user space task has a higher scheduling latency, it can be
	usefully set to allow achieving better deadlines for kernel tasks, when
	the scheduling latency is calibrated for user space tasks.
	For more precise results see the following options.

config RTAI_KERN_BUSY_ALIGN_RET_DELAY
	string "Delay to return to a switched in timed kernel task (ns)"
	default 0
	depends on RTAI_BUSY_TIME_ALIGN
	help
	The average time to return to the timed call function after switching 
	back to a kernel space task switch. 
	It is subtracted from the resume time of a timed task to avoid 
	a delayed return when a busy wait to align to the resume time is 
	requested.
	To calibrate it enable RTAI_BUSY_TIME_ALIGN and set this and the 
	following option to one, then run the calibration helper available 
	in RTAI.
	A zero value will skip the busy alignment, as if RTAI_BUSY_TIME_ALIGN
	was not set. Useful to allow the alignment application just to kernel 
	or user tasks. For example when a precise calibration for user space 
	is used, a kernel task will anticipate its timed resumption; so setting
	a positive value here and a zero for the corresponding option 
	below will allow applying the busy wait just to kernel tasks.

config RTAI_USER_BUSY_ALIGN_RET_DELAY
	string "Delay to return to a switched in timed user task (ns)"
	default 0
	depends on RTAI_BUSY_TIME_ALIGN
	help
	The average time to return to the timed call function after switching 
	back to a user space task switch. 
	It is subtracted from the resume time of a timed task to avoid 
	a delayed return when a busy wait to align to the resume time is
	requested.
	To calibrate it enable RTAI_BUSY_TIME_ALIGN and set this and the 
	previous option to one, then run the calibration helper available 
	in RTAI.
	A zero value will skip the busy alignment, as if RTAI_BUSY_TIME_ALIGN
	was not set. Useful to allow the alignment application just to kernel
        or user tasks.

config RTAI_SCHED_LXRT_NUMSLOTS
	string "Number of registrable RTAI objects"
	default 1024
	help
	The maximum number of registrable objects in RTAI.

config RTAI_MONITOR_EXECTIME
	bool "Display RTAI task execution time (in per thousand)"
	default y
	help
	If this option is enabled it is possible to see the time consumed by
	hard real time tasks, in per thousand of the total time available, 
	by using the RTAI scheduler proc file, e.g. "cat /proc/rtai/scheduler".
	Since this option uses the TSC it is better to avoid it in production
	for x86 CPUs not having TSCs, i.e. 486s and some untrue 586s.

config RTAI_ALLOW_RR
	bool "Allow round-robin scheduling"
	default y
	help
	By enabling this option it is possible to use round robin scheduling
	in RTAI, after enabling such a mode on a task by task basis through a
	call to a suitable scheduler function.

config RTAI_FULL_PRINHER
	bool "Enable full priority inheritance"
	default n
	help
	In RTAI resource semaphores, aka mutexes, support two ways to
	manage priority inheritance, both for resource semaphores and 
	intertask messages, blocked sent or rpced, to a task owning any
	resource semaphore already. Notice in fact that the task itself
	becomes a kind of "de facto" resource when any task blocks on it
	to exchange messages. 
	Without enabling this option a task owning any resource will
	recover its base priority only when it releases the very last
	resource it owns. So full priority inheritance will work as
	it is usually expected for a singly owned resource only because,
	whenever a task achieves the ownership of more than one resource,
	priority inheritance will become an adaptive dynamic priority
	ceiling. In such a case in fact the task priority is increased
	according to the highest priority task waiting on any resource
	a task owns, itself included because of messages being exchanged
	with it, but it will be returned to its base priority only when all
	owned resources are released. This is a compromise design choice
	aimed at avoiding searches for the new priority to be inherited
	across multiply owned resources and blocked tasks send/rpcing to
	the task.
	By enabling this configuration option instead you'll allow full
	priority inheritance, so that when a task releases any resource
	semaphore it owns it will acquire the priority of the most prioritary
	task, either waiting on any resource semaphore that it is still
	owned by the task or blocked send/rpcing to it.
	The choice is dependent on your needs mostly. Just take into account
	that the default dynamic priority ceiling is simpler, a bit more 
	effective and less deadlock prone than full priority inheritance.

config RTAI_ALIGN_LINUX_PRIORITY
	bool "Keep Linux task priority aligned to RTAI"
	default y
	help

	By enabling this option the RTAI scheduler will keep Linux tasks
	execution priority aligned to its. Naturally this makes sense
	either for Linux soft real time tasks enabled to use RTAI APIs, 
	i.e. they issued rt_task_init/rt_task_init_schmod, or when RTAI 
	hard real time tasks are given back to Linux. 

config RTAI_ONE_SHOT
	bool "One-shot timer mode"
	default y
	help
	Set to enable one-shot timer mode as the default. If not set, the 
	hard timer will run in periodic mode according to the period used 
	in start_rt_timer().
	Notice that whatever the default setting chosen it is possible to
	override it by specifically calling either rt_set_oneshot_mode() or 
	rt_set_periodic_mode() at run time.

config RTAI_CAL_FREQS_FACT
	string "Cure loosely calibrated frequencies - see help"
	default 0
	help
	This configuration parameter is meaningful for the oneshot mode only
	where it has two effects:
	1 - in oneshot mode using the APIC timer, i.e. always for SMP, a 
	precise scheduling time depends also on the ratio cpu_freq/apic_freq. 
	The best results can be achieved by using the RTAI calibration tool. 
	If no calibration is run one will rely on what Linux makes available 
	by default, which could be not precise enough, especially for not so 
	short timed intervals.
 	That leads to large and systematic latencies, especially in the case
	of low frequency schedules. By setting this option to a suitable
	value one can be sure that a certain firing frequency is granted 
	even when relatively large idle periods are encountered, thus
	limiting the overall latency with which long sleeping tasks might
	be awaken in case of imprecise calibrations of the above cited
	frequencies;
	2 - in the case of very long timed list it will limit the search 
	for the next firing time of widely scattered tasks with lowest 
	priorities, thus avoiding useless scheduling delays. The granted 
	firing interval will be roughly equal to:
	1.0/(RTAI_CAL_FREQS_FACT + 2.0) (seconds).

endmenu

menu "Supported services"

config RTAI_BITS
	tristate "Event flags"
	default m
	help
	Event flags are used to synchronize a task to the occurrence of 
	multiple events. RTAI uses the term "bits" to stress the fact that
	events are just logical objects, i.e. a kind of digital I/O, 
	nothing else being associated to them, e.g a count. 
	So any synchronization based on them may be disjunctive, when any 
	of the events have occurred, or conjunctive, when all events have 
	occurred. The former corresponds to a logical OR whereas the latter 
	is associated to a logical AND. Their use is similar to semaphores 
	except that signal/waits are not related to just a simple counter 
	but depends on the combination of set of bits.
	The module will be called rtai_bits.o.

config RTAI_FIFOS
	tristate "Fifo"
	default m
	help
	Originally fifos were used to allow communication between 
	kernel-space modules and user-space application. Even if fifos are 
	strictly no more required in RTAI, because of the native availability 
	of symmetric inter/intra kernel RTAI services, fifos are kept both 
	for compatibility reasons and because they are very useful tools to be
	used to communicate with interrupt handlers only based applications,
	since they do not require any scheduler to be installed.
	The module will be called rtai_fifos.o.

config RTAI_NETRPC
	tristate "Net RPC"
	depends on RTAI_MSG
	default y if RTAI_MSG=y
	default m if RTAI_MSG=m
	help
	RPC means Remote Procedure Call. The NetRPC implementation
	corresponds to a synchronous intertask message passing which
	is the old concept and the basis of microkernels, either
	distributed or not.  Using NetRPC makes from RTAI a
	distributed system, both for kernel and user space
	applications.
	NetRPC depends on a messaging support, if none is provided it relies
	on Linux network services, thus loosing strict real time. See the
	RTNet emulation option.
	The NetRPC module will be called rtai_netrpc.o.

config RTAI_NETRPC_RTNET
	bool "Use RTNet"
	depends on RTAI_NETRPC
	default n
	help
	This enable support of RTNet in NETRPC. By setting this parameters hard 
	real time will use RTNet automatically, while soft real time task will 
	use Linux networking. With this parameter set the making of RTAI will 
	work even if RTNet is not installed but you'll need RTNet to run it.
	Notice that the initial linking and set up of remote port stubs is 
	done in soft mode always.

config RTAI_RTNET_DIR
	depends on RTAI_NETRPC_RTNET
	string "RTNET installation directory"
	default "/usr/rtnet"
	help
	You Rhave chosen to use RTAI netrpc services with RTNet, so you have
	to tell where it is located.

config RTAI_SHM
	tristate "Shared memory"
	default m
	help
	This RTAI specific module allows sharing memory inter-intra
	real-time tasks and Linux processes. In fact it can be an
	alternative to the SYSTEM V shared memory. It may also be
	noticed that the services are symmetrical, i.e. the same calls
	can be used both in real-time tasks (within the kernel) and
	Linux processes.
	The module will be called rtai_shm.o.

config RTAI_SEM
	tristate "Semaphores"
	default m
	help
	A semaphore is a protocol mechanism offered to:
	  - control access to a shared resource (mutual exclusion);
	  - signal the occurrence of an event;
	  - allow two tasks to synchronize their activities.
	Resource semaphores can be recursively nested and support full
	priority inheritance, both among semaphore resources and
	intertask messages, for a singly owned resource.
	Priority inheritance becomes an adaptive priority ceiling when
	a task owns multiple resources, including messages sent to it.
	Both binary and counting semaphores are able to queue tasks
	either in FIFO or priority order and this can be chosen
	dynamically at run time.
	The module will be called rtai_sem.o.

config RTAI_RT_POLL
	bool "Enable IPCs polling"
	depends on RTAI_SEM
	default n
	help
	This enable polling support for RTAI services. At the moment only 
	MBXes and SEMs are supported. The related service is embedded in 
	the semaphores module.

config RTAI_RT_POLL_ON_STACK
	bool "Use the stack for rt_poll dynamic arrays"
	depends on RTAI_RT_POLL
	default n
	help
	This let rt_poll allocate its dynamic data directly on the stack. It is
	likely the most effective way but it can deplete the stack somewhat,
	especially on 64 bits architectures, if polling requests are large,
	say > 40. Notice that even with smaller polling sizes it might be
	important to limit stack usage also when heavy preemptions, very high
	task switching rates and interrupts flooding are expected.
	By disabling this parameter RTAI will use its real time memory
	allocation; with it the limits are just in the size you set for the
	RTAI dynamic heap and in a slightly greater overhead. So for reasons
	of cautiousness the default setting is not to use the stack.

config RTAI_MSG
	tristate "Message"
	default m
	help
	Direct synchronization by direct intertask messaging, either as fast
	single unsigned long messages or as extended arbitrarily sized
	messages. Both async and sync messages with replies can be used.
	QNX styled APIs are also available. Blocking messages exploit priority 
	inheritance, which becomes a dynamic ceiling when inheritances are 
	mixed with resource sems.
	The module will be called rtai_msg.o.

config RTAI_MBX
	tristate "Mailboxes"
	depends on RTAI_SEM
	default y if RTAI_SEM=y
	default m if RTAI_SEM=m
	help
	A mailbox corresponds to a pointer-size variable which is
	associated to a service provided by the kernel. It allows a
	task or an ISR to deposit a message (the pointer) into this
	mailbox.
	The RTAI mailbox implementation is very flexible as it allows
	to send any message size by using any mailbox buffer
	size. They are based on the First In First Out (FIFO)
	principle and on Last In First Out (LIFO) for urgent delivery.
	Mailboxes depend on semaphores.
	The module will be called rtai_mbx.o.


config RTAI_TBX
	tristate "RTAI message queues and typed mailboxes"
	depends on RTAI_SEM
	default y if RTAI_SEM=y
	default m if RTAI_SEM=m
	help
	RTAI message queues (msgq) are intertask processor messages that allow 
	exchanging prioritised messages of any size. Broadcasting of messages
	to all the waiting tasks is also possible.
	Legacy typed mailbox (TBX) services are recovered by using RTAI msgqs
	and afford a pre canned example of their use offering:
	1 - message broadcasting allowing to send a message to all the tasks 
	   that are pending on the same TBX;
	2 - urgent sending of messages: these messages are not enqueued, but 
	    inserted in the head of the queue, bypassing all the other 
	    messages already present in TBX;
	3 - a priority or fifo wakeup policy that may be set at runtime when 
	    creating the typed mailbox.
	Typed mailboxes depend on semaphores.
	The module will be called rtai_tbx.o.

config RTAI_TASKLETS
	tristate "Tasklets"
	default m
	help

	The tasklets module adds an interesting new feature along the
	line, pioneered by RTAI, of a symmetric usage of all its
	services inter-intra kernel and user space for both soft and
	hard real-time. The new services provided can be useful when
	you have many tasks, both in kernel and user space, needing to
	execute specific functions. Such functions are called tasklets 
	and can be of two kinds:
        - a simple tasklet;
        - timed tasklets (timers).
	The tasklets implementation of timed tasklets relies on a
	server support task that executes the related timer functions,
	either in oneshot or periodic mode, on the base of their time
	deadline and according to their user assigned priority.
	As explained above, plain tasklets are just functions executed
	depending on user defined events. Their execution needs no server 
	and is simply triggered by calling the user specified tasklet
	function at due time, either from a kernel task or interrupt
	handler in charge of their execution when they are needed.
	The module will be called rtai_tasklets.o.

	There are special signals tasklets also, natively built in always.
	They are much the same as tasklets and execute their handler
	function whenever they are triggered by any task, including their
	parent task. The notable difference against tasklets is that the
	task they serve is blocked till any of its signal handler is 
	executing. So they behave as standard signal handlers but without
	the need to restart a blocked signalled task, since there is no
	need to have it resumed to catch a signal. In fact signals can be 
	seen as much as software generated interrupts. See their APIs
	documentation in the code.
	The module will be called rtai_signal.o.

	Notice that, if the module version is chosen, this option activates
	the making of two different modules. At the moment the related
	services from user space are seen as LXRT expansions using slots
	1 and 2 respectively.

config RTAI_MQ
	tristate "POSIX-like message queues"
	depends on RTAI_SEM
	default y if RTAI_SEM=y
	default m if RTAI_SEM=m
	help
	RTAI pqueues implements the message queues section of Posix 1003.1d. 
	They provide kernel-safe message queues. Message queues depend on 
	semaphores.
	The module will be called rtai_mq.o.

config RTAI_CLOCK_REALTIME
	bool "Support for Posix CLOCK_REALTIME APIs"
	default y
	help
	The purpose here is mainly to activate the CLOCK_REALTIME timing 
	support in a few RTAI native services used behind POSIX APIs.
	CLOCK_REALTIME is the default POSIX timing option so it should be
	enabled for a full POSIX support but, if you are either not using 
	POSIX or can work with it using just the CLOCK_MONOTONIC timing, 
	it would be better to avoid enabling this option. It will save you 
	a test on a long long. Not too much of an overhead indeed, but why 
	paying for it if not needed?
	It is defaulted to "yes" just to stay on the safe side.

endmenu

menu "Other features"

config RTAI_USE_NEWERR
	bool "New return values of blocking RTAI APIs"
	default y
	help
	Return values for RTAI blocking APIs are a bit sketchy. That 
	is due to a long standing legacy dating back to DOS and 8 bits PCs,
	when saving a few "if"s might have been important. Whatever one's 
	opinion such a legacy has now been likely inherited by many well
	working existing RTAI applications, that might break with a new 
	error return scheme. In any case a better set of error return values 
	might be useful nowadays, so it has been added. With it one will be
	able to correctly infer more detailed reasons for error returns i.e.:
	- invalid requests (RTE_OBJINV),
	- async unblocking (RTE_UNBLKD),
	- timeouts (RTE_TIMOUT),
	- timer overruns (RTE_TMROVRN),
	- deletion of blocking objects (RTE_OBJREM).
	Thus the new scheme has been made configurable to allow RTAI users
	to choose what to do, without forcing any adaption for already 
	existing working applications.

config RTAI_MALLOC
	tristate "Real-time malloc support"
	default y
	help
	RTAI provides a real-time implementation of malloc(). This allows 
	real-time tasks to allocate and free memory safely while executing
	in the real-time domain. If it is not enabled kernel's kmalloc will
	be used. So disabling this option is acceptable if you'll care 
	to do any allocation while in Linux context only, i.e. at modules
	initialisation.
	The module will be called rtai_malloc.o.

config RTAI_USE_TLSF
	bool "Allocate memory using TLSF in place of BSD one"
	depends on RTAI_MALLOC
	default n
	help
	RTAI dynamic memory allocation support offers two different methods
	to allocate memory chunks. The default one is along the lines 
	illustrated in:
	"Design of a General Purpose Memory Allocator for the 4.3BSD Unix
	 Kernel" by Marshall K. McKusick. 
	By enabling this option the:
	"Two Levels Segregated Lists (TLSF)" as found at:
	http://rtportal.upv.es/rtmalloc/allocators/tlsf/
	will be used instead.
	Rough measures seems to indicate small differences between the two
	in term of alloc/free times, likely with BSD being better for the
	tested allocation sizes (up to a few KBs), but TLSF seems to have
	better, i.e. lower, fragmentation properties. In any case you should
	check it yourself within your own applications.

config RTAI_MALLOC_VMALLOC
	bool "Use vmalloc() support"
	depends on RTAI_MALLOC
	default y
	help
	RTAI's malloc support offers two different ways to allocate memory 
	chunks, i.e. kmalloc and vmalloc.
	The reasons for using vmalloc:
	- it is simpler to share allocated buffers with user space;
	- it doesn't have the size restrictions of kmalloc.
	The reasons for using kmalloc:
	- it is faster (not important since it as to be used in soft real time);
	- it exhibits contiguous buffer addressing needed for DMA controllers 
	  which don't have scattering/gathering capability.
	The default is using kmalloc()

config RTAI_MALLOC_HEAPSZ
	string "Size of the global heap (Kbytes)"
	depends on RTAI_MALLOC
	default 2048
	help
	RTAI pre-allocates a global heap as part of its initialization
	chores. This parameter allows to define its size (in
	kilobytes).

config RTAI_KSTACK_HEAPSZ
	string "Size of stacks heap for RTAI own kernel tasks (Kbytes)"
	depends on RTAI_MALLOC
	default 512
	help
	RTAI pre-allocates a heap for the stacks of its own kernel tasks.
	This parameter allows to define its size (in kilobytes).

config RTAI_TASK_SWITCH_SIGNAL
	bool "task switches specific signal"
	default n
	help
	RTAI can signal a task switch each time a task resumes execution.
	The way it is done depends on the execution space:
	- kernel: execute a function assigned at rt_task_init or by calling
	  rt_task_signal_handler;
	- user: install an RTAI own signal handler and have it called at any
	  task switch through its number, assigned by calling 
	  rt_task_signal_handler.
	The default is to not make available this feature, so you must enable
	it explicitly if it is useful for your application.

config RTAI_HARD_SOFT_TOGGLER
	bool "Install Linux signal handler to toggle hard-soft modes"
	default n
	help
	By setting this option RTAI will install a Linux signal (SIGUSR1) and 
	handler, when any of the available task-thread init functions is called
	to enable the usage of its own APIs. With it is possible to toggle the 
	hard-soft mode of any task, asynchronously and outside of it, by using 
	some form of KILL, i.e.: "kill -USR1 <pid>" from a shell, or 
	"kill(pid, SIGUSR1)" from a C function. For the latter case the helper 
	function "pid_t rt_get_linux_tid(RT_TASK *rt_task)" has been added to
	help in quickly getting the pid of the RTAI task extension "rt_task" 
	of a Linux task.

endmenu

endmenu

menu "Add-ons"

config RTAI_RTDM
	bool "Real-Time Driver Model over RTAI"
	default n
	help
	Real Time Drive Model specific implementation for RTAI.

config RTAI_RTDM_FD_MAX
	depends on RTAI_RTDM
	string "Number of RTDM file descriptors"
	default 512
	help
	The maximum number of file descriptors in RTDM.

config RTAI_RTDM_SELECT
	depends on RTAI_RTDM
	bool "Enable select multiplexing for RTDM services"
        default n
	help
	By enabling this option, select(2) support can be used to monitor
	access to multiple RTDM services all in one, as for the standard UNIX
	support, with the exception of the timeout argument format. Being it
	RTDM specific nanoseconds are used directly in place of 
	timeval/timespec.

config RTAI_RTDM_SHIRQ
	depends on RTAI_RTDM
        bool "Shared interrupts"
        default n
        help
        Make it possible for RTDM own interrupt handlers to manage shared
	interrupts.

config RTAI_DEBUG_RTDM
	depends on RTAI_RTDM
        bool "Enable some elementary RTDM debugging messages"
        default n
        help
        Enable some elementary debugging of wrong requests to RTDM, in the 
	form of messages asserting what's improper and where it's happening.

endmenu
